Wikipedia 

https://en.wikipedia.org/wiki/AI_control_problem


AI Safety Support

links page https://www.aisafetysupport.org/resources/lots-of-links

wishlist/bottleneck survey
https://forum.effectivealtruism.org/posts/2pxGXYX2JrptvLpzZ/ai-safety-career-bottlenecks-survey-responses-responses
(part career stuff, part resources and reading lists)


CHAI

Tiered bibliography https://humancompatible.ai/bibliography

(see also Critch/Russell berkeley course)

MIRI

motivations https://intelligence.org/why-ai-safety/


Forum posts

Sequences on alignment forum? Rohin Shah recommended these, and authored one.
Richard Ngo authored one.



Other

https://www.cser.ac.uk/research/risks-from-artificial-intelligence/

https://www.cnas.org/artificial-intelligence-and-global-security-reading-list

Apparently there's an active, open, AI safety slack (see AGISF slack for link)
