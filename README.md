# Artificial Intelligence and Society

This repository documents my (totally incomplete) exploration of the
philosophy of ethics and society with a particular interest in the future
role of artificial intelience. This will include both near-term and
long-term future issues.
The content is based on my reading, research, thought, coursework, 


This repository is a perpetual work in progress.
If we're lucky, one day it might become a website, or even a book (haha,
sure).
But seriously, if you want specific resources or progress or if you have
questions, just raise an issue.


#### Contents

* Coming soon:
  [Resources](resources.md):
  A collection of resources and links related to the topics of this project.
  Includes notable readings, other reading and resource lists, etc.

* [COMP90087 The Ethics of Artificial Intelligence](comp90087/):
  Unimelb's COMP90087 is an introduction to current issues in AI and society,
  framed using introductory moral philosophy.
  I joined the teaching team in the innaugural semester (2021).
  Here you can find some information about the subject and staff, the
  official syllabus, and a complete list of *readings!*

* Coming soon:
  [AGI Safety Fundamentals](agisf/):
  A fellowship (more of a reading group) from EA Cambridge, on research into
  the safety of generally intelligent AI systems.
  Here, find readings, and possibly some of my notes if I decide to take
  some throughout the program.
  The readings are already available online now:
  [Fellowship on AGI Fundamentals](https://www.eacambridge.org/agi-safety-fundamentals).

* WIP: [My notes on ethics and AI](my-notes-on-thecis-and-ai):
  My list of key topics, lessons, and readings, and some of my remaining
  questions.


## My notes on ethics and AI


Overall, the experience of teaching COMP90087 left me with many thoughts
and questions unresolved
(as can be expected of a subject aimed at students without a background in
philosophy).
Moreover I think the subject could have been organised into a more coherent
narrative (though the current form was understandable given the collaborative
nature of the subject's authorship).
One day I hope to find time to take a deeper dive into the underlying
moral philosophy of the issues we have discussed.

In this section I will give a list of key topics and ideas from the subject
(and beyond), with more emphasis on fundamentals and less on case studies and
examples, as suits my particualr interest. I will also note down important
lessons I have learned about the topics and the process of studying and
teaching them. Finally, I will refer to key readings (not all of which I have
yet gotten around to reading) and, importantly, key open questions (from my
perspective) left unanswered by COMP90087 where I would like to investigate
further some day.

### My rough syllabus

Here's a rough high-level syllabus/narrative if I were to try (however
underqualified I am) to put together a subject like this myself:

* The history of AI
* Philosophy of mind
* Moral philosophy / ethics
  * *Normative v. descriptive claims and ethical arguments*
  * Traditional ethical frameworks
    * Consequentialism and utilitarianism
    * Deontology and Kant's Categorical Imperative
    * Virtue Ethics
    * Ethics of Care
    * Principlism
    * *There are more!* Preferences? Theology? Stoicism? Economic growth?
      Etc.
  * Practical ethical guidelines
* Political philosophy---the law, policy, politics, governance (think
  about this structure more)
* Ethical principles
  * Trust
  * Fairness / justice
  * Accountability
  * Privacy and data
  * Transparency
  * Explainability
  * Accessibility
  * Equity
  * Rights
  * *Autonomy*
  * *Personhood*
* Technologies and issues
  * Automation
  * *Surveillance*
  * Facial recognition
  * Deepfakes
  * Automatic justice
* *Automated ethics?*
  * *Superintelligence*
  * *Reward learning and Beneficial AI*
* More?

---

> ### Lesson number 1: AI problems are often just people problems
> 
> At many points during lectures, discussions, and readings throughout the
> semester, I realised that if we took the AI out of the discussion (for
> example by mentally replacing the AI system with a human or a collection of
> humans), we would still have the same ethical issue to resolve. 
> Not all of the issues we discussed were inherently related to the AI!
> (Though the AI or technology sometimes magnified and/or distorted the
> issues.)
> 
> I think this observation can help us to resolve ethical issues:
> In the case where we can separate the "AI" part from the case study without
> fundamentally changing the ethical issue, we effectively reduce the problem
> a human problem, which is potentially easier to solve
> (and we can leverage the millenia of thought on moral and political
> philosophy that has come before the invention of AI systems to help us do
> so).
> 
> On the other hand, if replacing the AI with a human makes the problem go
> away, then it would seem that the human has some feature(s) which the AI is
> lacking and that this lack is causing the issue. Then identifying these
> missing features (the way humans solve the ethical problem) gives us a
> template by which we can solve the AI-ethical problem.
> 
> This explanation could benefit from some examples. Since this has been such
> a common theme, I'll attempt to reference it in my discussion throughout the
> rest of these notes.

---

> ### Lesson number 2: Interdisciplinary communication is hard (duh)
> 
> In conversations with the teaching team, I often had much more trouble
> comprehending and being comprehended than I am accustomed to. It turns out
> people from different disciplines can sometimes use the same words to mean
> completely different things. Okay, maybe I should have seen this coming, but
> it's one thing to say and another thing to experience. Anyway, since I am
> interested in pursuing multidisciplinary work in my research career, I will
> have to talk and collaborate with people from all kinds of disciplinary
> backgrounds. I had better remember this lesson and be aware of the language
> barriers when I am speaking, listening, reading, and writing!
