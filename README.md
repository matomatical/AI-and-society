# The Ethics of Artificial Intelligence


This repository documents my (totally incomplete) exploration of the field of
AI Ethics. So far most of the notes and resources are based on what I learned
as a tutor for *COMP90087 The Ethics of Artificial Intelligence* at the
University of Melbourne. This experience left me with many thoughts and
questions and so one day I hope to find time to take a deeper dive into the
underlying moral philosophy of the issues we have discussed.

#### Contents

This repository is a work-in-progress. Please feel free to raise an issue if
you want some more of that progress or have any other questions.

* COMP90087 The Ethics of Artificial Intelligence---some information about the
  subject, the staff, and the official syllabus.
* My notes on ethics and AI---my list of key topics, lessons, and readings,
  and some of my remaining questions.



### COMP90087 The Ethics of Artificial Intelligence

Semester 1, 2021, was the inaugural semester of the subject
[*COMP90087 The Ethics of Artificial Intelligence*](https://handbook.unimelb.edu.au/2021/subjects/comp90087)
at the University of Melbourne. This subject aims to introduce (mostly)
technical postgraduate students to topics in AI history, moral philosophy,
digital ethics, and digital law,
with an emphasis on the particular ethical issues raised by applications of AI
technologies.
(I guess) the hope is that this education will help these students think more
carefuly and responsibly about the ethical implications of their future work
as technologists.

That sounded like a great plan to me, and I had always wanted to sit down and
learn some moral philosophy for my own self-improvement, so I was excited to
apply to be a part of the teaching team, and I was honoured to be accepted as
a COMP90087 tutor!

#### Teaching team

The subject was developed by an interdisciplinary team of researchers, mostly
from the University's
[*Center for Artificial Intelligence and Digital Ethics (CAIDE)*](https://law.unimelb.edu.au/centres/caide/):

* [Professor Tim Miller](https://people.eng.unimelb.edu.au/tmiller/),
* [Dr Simon Coghlan](https://findanexpert.unimelb.edu.au/profile/787891-simon-coghlan),
* [Dr Marc Cheong](https://findanexpert.unimelb.edu.au/profile/862627-marc-cheong),
* [Professor Jeannie Patterson](https://law.unimelb.edu.au/about/staff/jeannie-paterson),
* [Dr Kobi Leins](https://findanexpert.unimelb.edu.au/profile/626407-kobi-leins), and
* Dr Michael Wildenauer,

with Michael, Kate Ferris, and *yours truly* delivering the weekly tutorials,
and Gabby Bush helping it all come together.

#### Subject syllabus

Each week was broadly focussed around a single topic. There was a prerecorded
lecture playlist from the subject developers along with a live seminar/chat,
some readings (see below). Oh, and a tutorial, that's where I came in!
Below is a list of topics by week:

1. Trust, machines, and digital ethics (Tim)
2. The History of Artificial Intelligence (Tim)
3. Philosophy and ethics (Simon)
4. Fairness and accountability (Simon)
5. Data governance (Marc)
6. Accessibility and equity (Marc)
7. Transparency---decisions & processes (Marc)
8. Explainability (Tim)
9. Policy, politics, and AI (Jeannie and Michael)
10. Frameworks and implementation (Michael)
11. AI and human rights (Michael)
12. Bringing it together (Simon)


---

### My notes on ethics and AI

On reflection, I feel like the subject could have been organised into a more
coherent narrative; and many of our discussions, though grounded in lots of
realistic case studies, could have delved deeper into the underlying moral
philosophy. In this section I will give a list of key topics and ideas from
the subject, with more emphasis on fundamentals and less on case studies and
examples, as suits my particualr interest. I will also note down important
lessons I have learned about the topics and the process of studying and
teaching them. Finally, I will refer to key readings (not all of which I have
yet gotten around to reading) and, importantly, key open questions (from my
perspective) left unanswered by COMP90087 where I would like to investigate
further some day.

#### My rough syllabus

* The history of AI
* Philosophy of mind
* Moral philosophy / ethics
  * *Normative v. descriptive claims and ethical arguments*
  * Traditional ethical frameworks
    * Consequentialism and utilitarianism
    * Deontology and Kant's Categorical Imperative
    * Virtue Ethics
    * Ethics of Care
    * Principlism
    * *There are more!* Preferences? Theology? Etc.
  * Practical ethical guidelines
* Political philosophy---the law, policy, politics, governance (think about this structure more)
* Ethical principles
  * Trust
  * Fairness / justice
  * Accountability
  * Privacy and data
  * Transparency
  * Explainability
  * Accessibility
  * Equity
  * Rights
  * *Autonomy*
  * *Personhood*
* Technologies and issues
  * Automation
  * *Surveillance*
  * Facial recognition
  * Deepfakes
  * Automatic justice
* *Automated ethics*
  * *Superintelligence*
  * *Reward learning and Beneficial AI*
* More?

---

> #### Lesson number 1: AI problems are often just people problems
> 
> At many points during lectures, discussions, and readings throughout the
> semester, I realised that if we took the AI out of the discussion (for
> example by mentally replacing the AI system with a human or a collection of
> humans), we would still have the same ethical issue to resolve. 
> Not all of the issues we discussed were inherently related to the AI!
> (Though the AI or technology sometimes magnified and/or distorted the
> issues.)
> 
> I think this observation can help us to resolve ethical issues:
> In the case where we can separate the "AI" part from the case study without
> fundamentally changing the ethical issue, we effectively reduce the problem
> a human problem, which is potentially easier to solve
> (and we can leverage the millenia of thought on moral and political
> philosophy that has come before the invention of AI systems to help us do
> so).
> 
> On the other hand, if replacing the AI with a human makes the problem go
> away, then it would seem that the human has some feature(s) which the AI is
> lacking and that this lack is causing the issue. Then identifying these
> missing features (the way humans solve the ethical problem) gives us a
> template by which we can solve the AI-ethical problem.
> 
> This explanation could benefit from some examples. Since this has been such
> a common theme, I'll attempt to reference it in my discussion throughout the
> rest of these notes.

---

> #### Lesson number 2: Interdisciplinary communication is hard (duh)
> 
> In conversations with the teaching team, I often had much more trouble
> comprehending and being comprehended than I am accustomed to. It turns out
> people from different disciplines can sometimes use the same words to mean
> completely different things. Okay, maybe I should have seen this coming, but
> it's one thing to say and another thing to experience. Anyway, since I am
> interested in pursuing multidisciplinary work in my research career, I will
> have to talk and collaborate with people from all kinds of disciplinary
> backgrounds. I had better remember this lesson and be aware of the language
> barriers when I am speaking, listening, reading, and writing!
