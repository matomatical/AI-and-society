# AGI Safety Fundamentals

A fellowship / faciliated reading group on foundational ideas in the study
of the safety of generally intelligent AI systems.
The fellowship is run by [EA Cambridge](https://www.eacambridge.org/).
The curriculum is curated by [Richard Ngo](http://thinkingcomplete.blogspot.com/p/about.html).

I was honoured to be accepted into the second iteration of the program,
starting in July 2021. The number of interested students was apparently
quite high, and so was the number of accepted students---I joined cohort 27.

More information about the fellowship, including materials, is available
[online](https://www.eacambridge.org/agi-safety-fundamentals).
This page will be my own version of the resource list, along with
any additional resources I think are relevant, and perhaps some notes
from my participation in the program.

## Syllabus

Each week consists of several readings on a common topic, and a facilitated
discussion session within cohorts. Below is a list of topics by week:

0. Introduction to machine learning
1. AGI and superintelligence
2. Goals and misalignment
3. Threat models and types of solutions
4. Learning from humans
5. Decomposing tasks for outer alignment
6. Other paradigms for safety work
7. AGI safety in context

The course will conclude with an optional, multi-week personal project
(e.g. blog post, literature rview, explanation, brainstorm, etc.)
to be discussed in a final, faciliated '8th' week.

The course does not have a single 'textbook', but along with acceptance into
the program came a free book from the three 'AI Safety' texts:

* Nick Bostrom, *Superintelligence*, 2015
* Stuart Russell, *Human Compatible*, 2019
* Brian Christian, *The Alignment Problem*, 2020

I requested the latter since I already had copies of the former two.


## Week 0: Introduction to machine learning

Skipped, but I should make a point to watch the lecture.

## Week 1: AGI and superintelligence

> What do we mean by artificial general intelligence, and how might we
> achieve it?

TODO: Reading, list resources.


